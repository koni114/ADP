## Chapter_01 데이터 처리 프로세스

### ETL(Extraction, Transaction and Load) 개요
---
> * 데이터 이동과 변환 절차와 관련된 업계 표준 용어  
> 데이터 웨어하우스(DW), 운영 데이터 스토어(ODS), 데이터 마트(DM)에 대한 데이터 적재 작업의 핵심 구성 요소  
> 데이터 통합, 데이터 이동, 마스터 데이터 관리에 걸쳐 폭넓게 활용  

> * ETL은 데이터 이동과 변환을 주 목적으로 하며, 3가지 기능으로 구성  
>  
>   + <b> ① Extraction(추출) </b>    
> 하나 또는 그 이상의 데이터 원천(Source)들로부터 데이터 획득  
>   + <b> ② Transformation(변환) </b>  
> 데이터 클랜징, 형식 변환, 표준화, 통합 또는 다수 애플리케이션에 내장된 비즈니스 룰 적용 등  
>   + <b> ③ Loading(적재) </b>  
> 위 변형 단계 처리가 완료된 데이터를 특정 목표 시스템에 적재  

> * ETL 작업 단계에는 <b> MPP(Massive Parallel Processing) </b> 를 지원    
> 또한 다수 시스템들간 대용량, 복잡도가 높은 비즈니스 룰 적용이 필요한 데이터 교환에 활용  

> * ETL 구현을 위한 여러 상용 S/W들이 있으며,  
> <b>일괄(Batch) ETL</b>과 <b>실시간(Real Time) ETL</b>로 구분  

### * ODC와 데이터 웨어하우스 개념도
> ![img](C://데이터분석자료/ADP준비자료/ODC.jpg)

> * Step 0 interface : 다양한 이기종 DBMS 및 스프레드시트 등 데이터 원천(Source)으로부터 데이터를 획득하기 위한 인터페이스 매커니즘 구현  

> * Step 1 Staging ETL : 수립된 일정에 따라 데이터 원천(Source)으로부터 트렌젝션 데이터 획득 작업 수행 후, 획득된 데이터를 스테이징 테이블에 저장  
> * Step 2 Profiling ETL : 스테이징 테이블에서 데이터 특성을 식별하고 품질을 측정  
> * Step 3 Cleansing ETL : 다양한 규칙들을 활용해 프로파일링된 데이터 보정 작업  
> * Step 4 Integration ETL : (이름, 값, 구조) 데이터 충돌을 해소하고, 클렌징된 데이터를 통합  
> * Step 5 Denormalizing ETL : 운영 보고서 생성, 데이터 웨어 하우스 또는 데이터 마트 데이터 적재를 위해 데이터 비정규화 수행  

### ODS(Operational Data Store) 구성  
---
> * 데이터 추가 작업을 위해 다양한 데이터 원천(Source)들로부터의 데이터 추출, 통합한 DB  
> * 향후 비즈니스 지원을 위해 타 정보 시스템으로 이관, 다양한 보고서 생성을 위해 DW로 이관  
> * 다양한 원천 소스 데이터가 통합되기 때문에 데이터 클랜징, 중복 제거, 데이터 무결성 점검 등의 작업을 포함  

> ![img](C://데이터분석자료/ADP준비자료/LayeredODC.jpg)

> <b> ① interface Layer </b>
> * 다양한 데이터 원천들로부터 데이터를 획득하는 단계  
> * 데이터를 획득하기 위한 프로토콜로는 OLEDB, ODBC, FTP 등과 더불어 DW의 Real Time, Near Real Time OLAP  
> * 질의를 지원하기 위해 실시간 데이터 복제 인터페이스 기술들이 함께 활용됨  

> <b> ②Staging Layer </b>  
> * 작업 일정이 통제되는 프로세스들에 의해 데이터 원천들로부터 트랜잭션 데이터(어느정도 변화된 데이터)들이 추출  
> * 하나 또는 그 이상의 스테이징 테이블들에 저장  
> * 정규화 배제  
> * 테이블 스키마는 데이터 원천의 구조에 의존적  
> * 데이터 매핑은 1:1, 1: N(원천Source : Staging Table) 구조를 가짐  
> * 데이터가 스테이징 테이블에 적재되는 시점에 control 정보도 동시에 저장  
> * Batch 작업 형태와 Real Time 형태의 데이터 획득 방식을 혼용해 구성할 수 있음  

> <b> ③ Profiling Layer </b>
> * 범위, 도메인, 유일성 확보 등의 규칙을 기준으로 데이터 품질 점검 실시  
> Step1 : 데이터 프로파일링 수행  
> Step2 : 데이터 프로파일링 결과 통계 처리  
> Step3 : 데이터 <b> 품질 보고서 생성 </b> 및 공유  

> <b> ④ Cleansing Layer </b>
> * 클렌징 ETL process 들로 앞데이터 프로파일링 단계에서 식별된 오류 데이터를 수정  
> Step 1 : cleansing Stored Procedure  
> Step 2 : Cleasing ETL Functions  

> <b> ⑤ data Integration Layer </b>
> * 앞서 수정 완료한 데이터를 ODS 내에 단일 통합 테이블에 적재  
> * 선행자료 및 조건 : 데이터 클랜징 테이블, 데이터 충돌 판단 요건  
> Step 1 : Integration Stored Procedure 실행  
> Step 2 : Integration ETL Functions 실행  

> <b> ⑥ Export Layer </b>
> * export rule 과 security rule을 반영한 익스포트 ETL 기능을 수행해 Export 테이블을 생성  
> * DBMS 클라이언트, Data Mart, DW에 적재  
> * OLAP에 활용될 수 있음  

### 데이터 웨어하우스(Data Warehouse)
---
> * DW의 특징  
>   + ① 주제 중심(Subject Oriented)  
> 특정 이벤트나 업무 항목을 기준으로 구조화  
>   + ②영속성(Non Volatile)  
> 최초 저장 이후에는 읽기 전용 속성을 가지며, 삭제되지 않음  
>   + ③통합성(Integrated)  
> DW 데이터는 기관, 조직이 보유한 대부분의 운영 시스템들에 의해 생성된 데이터 통합본  
>   + ④시계열성(Time Variant)  

> * DW Table들은 <b>Star Schema</b>  또는 <b> Snow Flake Schema </b> 로 모델링 됨  
>   + ① Star Schema  
> 조인 스키마라고도 함. DW 스키마 중 가장 단순. 사실 테이블을 중심으로, 차원 테이블로 구성  
> 전통적인 관계형 DB를 통해 다차원 DB 기능 구현 가능  
> 이해하기 쉽고, join table 개수가 적고, 쿼리 작성이 용이  
> 비정규화에 따른 데이터 중복으로 테이블 적재 시 오래걸리는 단점 존재  
>   + ② Snow Flake Schema  
> 스타 스키마의 차원 테이블을 제3정규형으로 정규화한 형태  
> 데이터의 중복이 제거돼 데이터 적재시 시간 단축  
> Join Table의 증가로 쿼리 작성 난이도 상승  

### CDC(Change Data Capture) 개요
---
> * DB 내 데이터의 변경을 식별해 필요한 후속 처리를 자동화하는 기술 또는 설계 기법이자 구조  
> * 실시간 또는 근접 실시간 데이터 통합을 기반으로 하는 DW 및 저장소 구축에 폭 넓게 사용  

> * ####  CDC 구현 기법  
>   + <b> ① Time Stamp on Rows </b>   
> 테이블 내 마지막 변경 시점을 기록하는 TimeStamp 컬럼을 두고, 마지막 변경 TimeStamp 값 보다 더 최신 컬럼을
> 변경된 레코드로 식별
>   +  <b> ② Version Numbers on Rows </b>
> 레코드의 버전을 기록하는 컬럼을 두고, 기 식별된 레코드의 버전보다 더 높은 레코드를 변경 된 것으로 식별  
> 레코드들의 최신 버전을 기록 관리하는 참조 테이블을 함께 운용하는 것이 일반적  
>   + <b> ③ Status on Rows </b>
> Time Stamp 및 Version Rows 의 보완 용도로 사용.  
> 변경 여부를 True/False boolean 값으로 저장하는 컬럼의 상태 값을 기반으로 변경 여부 결정  
> 시간이나 버전에 따른 식별 여부에 추가적으로 사람이 판단한 업무 규칙을 추가할 수 있음  
>   + <b> ④Time/Version/Status on Rows </b>   
> TimeStamp, version, Status 모두 활용하는 기법.  
> 정교한 쿼리를 이용해 개발 유연성 제공  
>   + <b> ⑤ Triggers on Tables </b>
> DB 트리거를 활용해 사전에 등록된 다수 대상 시스템에 변경 데이터를 베포하는 형태로 CDC를 구현  
> DB 트리거는 시스템 관리 복잡도를 증가하고 유지보수성을 저하시키는 특성이 있어 사용 주의  
>   + <b> ⑥ Event Programming </b>
> 데이터 변경 식별 기능을 Application에 구현  
> Application 개발 부담과 복잡도를 증가시키나, 다양한 조건에 의한 CDC 매커니즘을 구현할 수 있는 기법  
>   + <b> ⑦ Log Scanner on Database </b>
> DB 데이터에 대한 변경 여부와 변경 값 시간 등을 transaction 로그를 기록 관리하는 기능 제공  
> 트랜잭션 로그에 대한 스캐닝 및 변경 내역에 대한 해석을 통해 CDC 매커니즘 수행  
> DBMS 종류에 따라 작업 규모가 증가할 수 있음  

> * ##### CDC 장점  
>    + DB 영향도 최소화  
>   + DB 사용 Application에 대한 영향도 최소화  
>   + 변경 식별 지연시간 최소화  
>   + 트랜잭션 무결성에 대한 영향도 최소화  
>   + DB 스키마 변경 불필요  

> * ##### CDC 구현 방식  
>     + CDC 구현 시, 데이터 원천에서 변경을 식별하고 대상 시스템에 변경 데이터를 적재해 주는 <b>'Push' 방식 </b>  
>   + 대상 시스템에서 데이터 원천을 정기적으로 살펴보아 필요 시 데이터를 다운로드 하는 <b>'Pull' 방식 </b>  

### EAI(Enterprise Application Integration)
---
> * ##### EAI 개요
>   + 기업 정보 시스템들의 데이터를 연계, 통합하는 SW 정보 시스템 아키텍처 프레임워크  
>   + 이질적 정보 시스템들의 데이터를 연계함으로써 상호 융화 내지 동기화돼 동작  
>   + 프론트 오피스 시스템, 기존의 레거시 시스템, 패키지 어플리케이션 등의 형태로 산재된 정보 시스템들을 프로세스 및 메세지 차원에서 통합,관리 할 수 있게 함  

> * ##### Point To Point 방식  
>   + EAI 시스템 하위 버전  
>   + 기존 단위 업무 위주의 정보 시스템 개발 시, 데이터 연계의 복잡성 발생  
>   + 정보 시스템간 데이터 통합과 연계 확보를 어렵게 하고, 마스터 데이터의 통합과 표준화를 불가능하게 함  
>   + 이는 유지보수성을 저하 시킴  
> -> 이를 해결하기 위해 <b>Hub and spoke </b> 방식의 EAI 기반 구조를 적용할 수 있음  

> * ##### EAI 구성 요소
> ![img](C://데이터분석자료/ADP준비자료/EAI요소.jpg)
> * 정보 시스템과 EAI 허브(Engine) 간 연결성을 확보하기 위한 Adapter 들이 존재  
>   + <b> BUS </b>            : Adapter들을 매개로 각 정보 시스템들 간의 데이터 연동 경로  
>   + <b> Broker </b>          : 데이터 연동 규칙 통제  
>   + <b> Transformer </b> : 데이터 형식 변환 등을 담당  

> * ##### EAI 구현 유형  
>   + <b> ① Meditation(intra-communication) </b>  
> EAI 엔진이 중개자(Broker)로 동작  
> 특정 정보 시스템 내 유의미한 이벤트 발생을 식별해,   
> 사전 약속된 정보 시스템들에게 그 내용을 전달  
>   + <b> ② Federation(inter-communication)  </b>  
> EAI 엔진이 외부 정보 시스템으로부터의 데이터 요청들을 일괄적으로 수령해 필요한 데이터 전달  

> ** intra VS inter
> intra : 어떤 것의 내부를 지칭, 어떤 scope가 핵심이 됨
> inter : 어떤 것과 다른 것의 상호 관계

### 데이터 연계 및 통합 기법 요약
---
>* ##### 데이터 연계 및 통합 유형(동기화기준)  
>   + 일괄 작업 시 ->  대용량 데이터의 처리가 가능  
>   + 실시간 통합 시 ->  관심 대상 영역 상태에 대한 빠른 파악 및 대응이 가능
> <b> Complex Event Processing </b> 이라는 아키텍처로 구현 가능  
> 데이터 중복을 허용하는 <b> 빅데이터 저장 인프라 스트럭처 </b> 의 활용과 병행 설계  

>* ##### 데이터 연계에 따른 EAI 기술 변화
>   + before : 데이터 웨어하우스 구성  
>   + after : ODS, BI Platform, MDM hub, hadoop Cloud 환경 등..  
>   + 비정형 또는 준정형 데이터를 정형 데이터로의 변환은 빅데이터의 주요한 기술적 특성  

### 대용량 비정형 데이터 처리
---
> * ##### 대용량 로그 데이터 수집
> 최근 사용자 행태 분석 등 기업의 주요 비즈니스 영역인 마케팅과 영업 전략 등에 필수적인 정보를 생성하는 데 사용  
> * ##### 비정형 데이터 수집 시스템 특징  
>   + <b> ① 초고속 수집 성능과 확장성 </b>  
> 실시간으로 발생하는 대용량 데이터를 놓치지 말아야 함    
> 증가한 서버 수만큼 에이전트의 수를 늘리는 방식으로 손쉽게 확장 가능  
>   + <b> ② 데이터 전송 보장 메커니즘 </b>  
> 수집한 데이터는 처리, 분석을 위한 저장소인 Hadoop, DB, NoSQL 등에 저장  
> 단계별로 전송될 때마다 신호를 주고 받아서 단 하나의 이벤트도 유실되지 않도록 함  
> 성능과 안정성은 Trade-Off 관계  
>   + <b> ③ 다양한 수집과 저장 플러그인 </b>  
> 몇 가지 설정만으로 데이터를 수집할 수 있도록 내장 플러그인들을 제공해야 함  
>   + <b> ④ 인터페이스 상속을 통한 애플리케이션 기능 확장 </b>  
> 업무 기능을 수정해야 할 경우, 인터페이스를 확장해 원하는 부분만 비즈 용도에 맞게 수정할 수 있어야 함  
> 대표 오픈소스 데이터 수집 시스템 Flume-NG  
> > ![img](C://데이터분석자료/ADP준비자료/Flume_NG.jpg)  

> * ##### 대규모 분산 병렬 처리  
>   + 데이터가 대용량이라면, 하둡 사용에 대한 검토 필요  

### 하둡(Hadoop)
> 대규모 분산 병렬 처리의 업계 표준인 맵리듀스(MapReduce) 시스템과 분산 파일 시스템인 HDFS로 구성된 플랫폼    
> * ##### 선형적인 성능과 용량 확장  
>   + 하둡을 구축함은 여러 대의 서버로 클러스터를 만든다는 의미  
>   + 클러스터 내 서버 5대가 최소 대수  
>   + 서버 대수 추가에 비례해 연산 기능과 저장 기능 증가 -> 비공유 분산 아키텍처 시스템이기 때문  
>   + 선형적인 확장도 가능
> * ##### 고장 감내성
>   + <b> 3중 복제 </b>가 돼 서로 다른 물리서버에 저장
>   + 특정 서버에 장애가 발생하더라도 데이터 유실 방지 할 수 있음
>   + 고장 감내 기능은 관리자의 개입 없이 시스템 수준에서 자동으로 동작
> * ##### 핵심 비즈니스 로직에 집중
>   + 시스템 수준에서 발생하는 장애 상황이나 확장성, 성능 등의 이슈는 내부적으로 최적화 해 처리  
> * ##### 풍부한 에코시스템 형성 **
>   하둡 같은 인프라 시스템에서 동작하는 다양한 응용 기술이 필요  
>   + 데이터 수집 기술 : Flume-NG  
>   + 데이터 연동 기술 : Sqoop  
>   + 데이터베이스 기술 NoSQL : Hbase  
>   + 대용량 SQL 질의 기술 : Hive, Pig  
>   + 실시간 SQL 질의 기술 : Impala, Tajo  
>   + 워크플로우 관리 기술 : Oozie, Azkaban 등  

### 데이터 연동
> * 비정형 데이터를 통해 분석을 하려면, 기업 내에 축적된 데이터와 정보를 연동하는 것이 필요  
> * DB를 대상으로 맵리듀스와 같은 대규모 분산 처리를 하는 것은 심한 부하를 야기  
> * <b> DB의 데이터를 Hadoop으로 복사 한 후, Hadoop에서 대규모 분산 병렬 처리를 수행 </b>
> * 대표적인 오픈 소스로 SQOOP 이 있음

### Sqoop
> * 하둡과 DB 연동 솔루션
> * MySQL, PPAS, 사이베이스 등 JDBC 지원 등 대부분 RDBS 와 연동
> * Hbase와 같은 NoSqQL DB와도 연동이 가능
> * 스쿱을 이용해 DB에서 Hadoop으로 데이터 전송하는 Script
>   + 데이터를 가져올 DB 접속 정보 입력
>   + 가져올 데이터에 대한 SQL 입력
>   + 몇 개의 프로세스를 실행하여 데이터를 가져올지 지정
>   프로세스를 많이 지정하면 빠르게 가져오겠지만, 부하 발생
>   + DB 키 컬럼 입력
>   + 가져온 데이터를 저장할 Hadoop 경로 입력

### Hive - 대용량 질의 도구
> * 하둡에서 SQL을 사용하여 하둡 상의 데이터를 쉽게 처리하고 분석 할 수 있도록 해주는 도구  
> * 대용량 데이터를 배치 처리하는 데 적합
> * 데이터를 실시간으로 조회하거나 처리해야 할 일들이 많음 -> Hive는 제약 존재
> * 최근 실시간 SQL 질의 분석 기술로 SQL on Hadoop 기술이 각광받고 있음
> 다음과 같은 기술들이 시장에 나온 상태
>   + 아파치 드릴(Drill)
>   + 아파치 스팅거(Stinger)
>   + 아파치 샤크(Shark)
>   + 아파치 타조(Tajo)
>   + 임팔라(Impala)
>   + 프레스토

### Impala - SQL on Hadoop
> * 기본적으로 하이브 SQL 지원. 모든 SQL문을 지원하는 것은 아님
> * Impala 주요 구성 요소
>   + <b> 클라이언트 </b> : ODBC, JDBC 클라이언트, 임팔라쉘 같이 Impala에 접속하여 테이블 관리, 데이터 조회 등의 작업 수행   
>   + <b> 메타스토어 </b> : Impala로 분석할 대상 데이터의 정보 관리. Hive의 메타데이터 같이 사용
>   + <b> Impala 데몬 </b>  : 클라이언트의 SQL 질의를 받아 데이터 file들의 읽기/쓰기 작업 수행
>   + <b> 스테이트스토어  </b> : 임팔라 데몬의 health 정보 관리
>   + <b> 스토리지 </b>  : Hbase, HDFS 두가지 지원

> * 기본적으로 모든 노드에 임팔라 데몬이 구동 됨
> * 이 데몬들이 구동된 임의의 노드에 JDBC나 ODBC 또는 임팔라쉘을 이용하여 질의 요청 가능
> * 사용자 함수 지원, 데이터 조인 시 메모리 문제 등 여러가지로 개선해야 할 사항들이 아직 있음

### 용어 정리
> * <b> 트랜잭션(transaction) </b>
> 데이터베이스의 상태를 변화 시키기 위한 수행 작업 단위  

> * <b> 스태이징(staging) </b>
> 소스시스템으로부터 제공 받은 데이터를 아무런 변화 없이 그대로 로딩하는 저장 공간  
> Temporary 성 공간  

> * <b> OLE(Object Linkng and Embedding) </b>
> 애플리케이션 사이에서 데이터를 공유하는 기술  

> * <b> ODBC(Open DataBase Connectivity) </b>
> 데이터베이스 표준 규격, 데이터베이스의 차이는 ODBC 드라이버에 흡수되기 때문에 사용자는  
> ODBC에 정해진 순서에 따라서 프로그램을 쓰면 접속처의 DB 종류 상관없이 접근 가능  

> * <b> Data Profiling </b>
> 프로파일링이란 데이터 품질 측정 대상 데이터베이스의 데이터를 읽어 컬럼, 테이블의 데이터 현황정보를 통계적으로   분석하는 것을 의미  

> * <b> OLAP(Online Analytics Processing) </b>
>   + 대용량 업무 DB를 구성하고, BI를 지원하기 위해 사용되는 기술
> DW나 Data Mart와 같은 대규모 데이터에 대해 <b>최종 사용자가   
> 정보에 직접 접근하여 정보를 분석</b>하고 의사결정에 활용할 수 있는 실시간 분석 처리.  
>   + 최종 사용자들이 전산 부서를 거치지 않고 자신이 직접 분석 데이터에 접근
